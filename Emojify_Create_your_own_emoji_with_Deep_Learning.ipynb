{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import"
      ],
      "metadata": {
        "id": "QIw7_YquDJqG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4MbUBknkbIP"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D\n",
        "from keras.optimizers import adam_v2\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Initialise the training and validation generators:**\n"
      ],
      "metadata": {
        "id": "AE9SMWKvDO5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"/content/drive/MyDrive/ML Projects/Face/train\"\n",
        "val_dir = \"/content/drive/MyDrive/ML Projects/Face/test\"\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(48,48),\n",
        "        batch_size=64,\n",
        "        color_mode=\"grayscale\",\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "        val_dir,\n",
        "        target_size=(48,48),\n",
        "        batch_size=64,\n",
        "        color_mode=\"grayscale\",\n",
        "        class_mode='categorical')"
      ],
      "metadata": {
        "id": "DE0ZmLyKlLr-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5215ab29-c07e-48e2-b359-3f970721a0cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 28719 images belonging to 7 classes.\n",
            "Found 7178 images belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build the convolution network architecture**"
      ],
      "metadata": {
        "id": "3yxVHzAPDhhz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_model = Sequential()\n",
        "\n",
        "emotion_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\n",
        "emotion_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "emotion_model.add(Dropout(0.25))\n",
        "\n",
        "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "emotion_model.add(Dropout(0.25))\n",
        "\n",
        "emotion_model.add(Flatten())\n",
        "emotion_model.add(Dense(1024, activation='relu'))\n",
        "emotion_model.add(Dropout(0.5))\n",
        "emotion_model.add(Dense(7, activation='softmax'))"
      ],
      "metadata": {
        "id": "aCI5azKZB0y9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compile and train the model:**"
      ],
      "metadata": {
        "id": "XUt6JRaWD0r7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_model.compile(loss='categorical_crossentropy',optimizer=adam_v2.Adam(lr=0.0001, decay=1e-6),metrics=['accuracy'])\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "model_path = \"/content/drive/MyDrive/ML Projects/Face/face_predict.h5\"\n",
        "checkpoint = ModelCheckpoint(model_path,monitor = 'val_accuracy',verbose =1, save_best_only = True,mode ='max')\n",
        "callbacks_list = [checkpoint]\n",
        "emotion_model_info = emotion_model.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=28709 // 64,\n",
        "        epochs=50,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=7178 // 64,\n",
        "        callbacks = callbacks_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Eq-uQwgDEGV",
        "outputId": "c7f5f0d6-8d8f-4593-e895-567bfe966bda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  if sys.path[0] == '':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "448/448 [==============================] - ETA: 0s - loss: 1.8018 - accuracy: 0.2591\n",
            "Epoch 1: val_accuracy improved from -inf to 0.31892, saving model to /content/drive/MyDrive/ML Projects/Face/face_predict.h5\n",
            "448/448 [==============================] - 74s 149ms/step - loss: 1.8018 - accuracy: 0.2591 - val_loss: 1.7182 - val_accuracy: 0.3189\n",
            "Epoch 2/50\n",
            "448/448 [==============================] - ETA: 0s - loss: 1.6260 - accuracy: 0.3687\n",
            "Epoch 2: val_accuracy improved from 0.31892 to 0.41099, saving model to /content/drive/MyDrive/ML Projects/Face/face_predict.h5\n",
            "448/448 [==============================] - 51s 115ms/step - loss: 1.6260 - accuracy: 0.3687 - val_loss: 1.5362 - val_accuracy: 0.4110\n",
            "Epoch 3/50\n",
            "448/448 [==============================] - ETA: 0s - loss: 1.5188 - accuracy: 0.4161\n",
            "Epoch 3: val_accuracy improved from 0.41099 to 0.44545, saving model to /content/drive/MyDrive/ML Projects/Face/face_predict.h5\n",
            "448/448 [==============================] - 51s 113ms/step - loss: 1.5188 - accuracy: 0.4161 - val_loss: 1.4617 - val_accuracy: 0.4455\n",
            "Epoch 4/50\n",
            "448/448 [==============================] - ETA: 0s - loss: 1.4516 - accuracy: 0.4464\n",
            "Epoch 4: val_accuracy improved from 0.44545 to 0.47377, saving model to /content/drive/MyDrive/ML Projects/Face/face_predict.h5\n",
            "448/448 [==============================] - 52s 116ms/step - loss: 1.4516 - accuracy: 0.4464 - val_loss: 1.3866 - val_accuracy: 0.4738\n",
            "Epoch 5/50\n",
            "448/448 [==============================] - ETA: 0s - loss: 1.3902 - accuracy: 0.4746\n",
            "Epoch 5: val_accuracy improved from 0.47377 to 0.47810, saving model to /content/drive/MyDrive/ML Projects/Face/face_predict.h5\n",
            "448/448 [==============================] - 51s 114ms/step - loss: 1.3902 - accuracy: 0.4746 - val_loss: 1.3679 - val_accuracy: 0.4781\n",
            "Epoch 6/50\n",
            "448/448 [==============================] - ETA: 0s - loss: 1.3406 - accuracy: 0.4923\n",
            "Epoch 6: val_accuracy improved from 0.47810 to 0.50167, saving model to /content/drive/MyDrive/ML Projects/Face/face_predict.h5\n",
            "448/448 [==============================] - 51s 113ms/step - loss: 1.3406 - accuracy: 0.4923 - val_loss: 1.3068 - val_accuracy: 0.5017\n",
            "Epoch 7/50\n",
            "448/448 [==============================] - ETA: 0s - loss: 1.3016 - accuracy: 0.5077\n",
            "Epoch 7: val_accuracy improved from 0.50167 to 0.52134, saving model to /content/drive/MyDrive/ML Projects/Face/face_predict.h5\n",
            "448/448 [==============================] - 53s 118ms/step - loss: 1.3016 - accuracy: 0.5077 - val_loss: 1.2751 - val_accuracy: 0.5213\n",
            "Epoch 8/50\n",
            "448/448 [==============================] - ETA: 0s - loss: 1.2649 - accuracy: 0.5210\n",
            "Epoch 8: val_accuracy improved from 0.52134 to 0.53055, saving model to /content/drive/MyDrive/ML Projects/Face/face_predict.h5\n",
            "448/448 [==============================] - 51s 114ms/step - loss: 1.2649 - accuracy: 0.5210 - val_loss: 1.2462 - val_accuracy: 0.5306\n",
            "Epoch 9/50\n",
            "448/448 [==============================] - ETA: 0s - loss: 1.2305 - accuracy: 0.5369\n",
            "Epoch 9: val_accuracy improved from 0.53055 to 0.54227, saving model to /content/drive/MyDrive/ML Projects/Face/face_predict.h5\n",
            "448/448 [==============================] - 51s 114ms/step - loss: 1.2305 - accuracy: 0.5369 - val_loss: 1.2155 - val_accuracy: 0.5423\n",
            "Epoch 10/50\n",
            "448/448 [==============================] - ETA: 0s - loss: 1.1999 - accuracy: 0.5476\n",
            "Epoch 10: val_accuracy did not improve from 0.54227\n",
            "448/448 [==============================] - 50s 112ms/step - loss: 1.1999 - accuracy: 0.5476 - val_loss: 1.2236 - val_accuracy: 0.5352\n",
            "Epoch 11/50\n",
            "448/448 [==============================] - ETA: 0s - loss: 1.1727 - accuracy: 0.5591\n",
            "Epoch 11: val_accuracy improved from 0.54227 to 0.55120, saving model to /content/drive/MyDrive/ML Projects/Face/face_predict.h5\n",
            "448/448 [==============================] - 51s 113ms/step - loss: 1.1727 - accuracy: 0.5591 - val_loss: 1.1872 - val_accuracy: 0.5512\n",
            "Epoch 12/50\n",
            "448/448 [==============================] - ETA: 0s - loss: 1.1436 - accuracy: 0.5719\n",
            "Epoch 12: val_accuracy improved from 0.55120 to 0.55622, saving model to /content/drive/MyDrive/ML Projects/Face/face_predict.h5\n",
            "448/448 [==============================] - 51s 114ms/step - loss: 1.1436 - accuracy: 0.5719 - val_loss: 1.1677 - val_accuracy: 0.5562\n",
            "Epoch 13/50\n",
            "448/448 [==============================] - ETA: 0s - loss: 1.1159 - accuracy: 0.5815\n",
            "Epoch 13: val_accuracy did not improve from 0.55622\n",
            "448/448 [==============================] - 50s 113ms/step - loss: 1.1159 - accuracy: 0.5815 - val_loss: 1.1717 - val_accuracy: 0.5545\n",
            "Epoch 14/50\n",
            "448/448 [==============================] - ETA: 0s - loss: 1.0933 - accuracy: 0.5909\n",
            "Epoch 14: val_accuracy improved from 0.55622 to 0.56557, saving model to /content/drive/MyDrive/ML Projects/Face/face_predict.h5\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 1.0933 - accuracy: 0.5909 - val_loss: 1.1371 - val_accuracy: 0.5656\n",
            "Epoch 15/50\n",
            "448/448 [==============================] - ETA: 0s - loss: 1.0703 - accuracy: 0.5999\n",
            "Epoch 15: val_accuracy improved from 0.56557 to 0.57422, saving model to /content/drive/MyDrive/ML Projects/Face/face_predict.h5\n",
            "448/448 [==============================] - 51s 113ms/step - loss: 1.0703 - accuracy: 0.5999 - val_loss: 1.1280 - val_accuracy: 0.5742\n",
            "Epoch 16/50\n",
            "448/448 [==============================] - ETA: 0s - loss: 1.0459 - accuracy: 0.6111\n",
            "Epoch 16: val_accuracy did not improve from 0.57422\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.0459 - accuracy: 0.6111 - val_loss: 1.1169 - val_accuracy: 0.5734\n",
            "Epoch 17/50\n",
            "448/448 [==============================] - ETA: 0s - loss: 1.0238 - accuracy: 0.6187\n",
            "Epoch 17: val_accuracy improved from 0.57422 to 0.57910, saving model to /content/drive/MyDrive/ML Projects/Face/face_predict.h5\n",
            "448/448 [==============================] - 50s 112ms/step - loss: 1.0238 - accuracy: 0.6187 - val_loss: 1.1172 - val_accuracy: 0.5791\n",
            "Epoch 18/50\n",
            "448/448 [==============================] - ETA: 0s - loss: 1.0021 - accuracy: 0.6266\n",
            "Epoch 18: val_accuracy improved from 0.57910 to 0.58287, saving model to /content/drive/MyDrive/ML Projects/Face/face_predict.h5\n",
            "448/448 [==============================] - 49s 110ms/step - loss: 1.0021 - accuracy: 0.6266 - val_loss: 1.0989 - val_accuracy: 0.5829\n",
            "Epoch 19/50\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.9765 - accuracy: 0.6384\n",
            "Epoch 19: val_accuracy improved from 0.58287 to 0.59082, saving model to /content/drive/MyDrive/ML Projects/Face/face_predict.h5\n",
            "448/448 [==============================] - 49s 109ms/step - loss: 0.9765 - accuracy: 0.6384 - val_loss: 1.1014 - val_accuracy: 0.5908\n",
            "Epoch 20/50\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.9565 - accuracy: 0.6448\n",
            "Epoch 20: val_accuracy improved from 0.59082 to 0.59166, saving model to /content/drive/MyDrive/ML Projects/Face/face_predict.h5\n",
            "448/448 [==============================] - 49s 109ms/step - loss: 0.9565 - accuracy: 0.6448 - val_loss: 1.0848 - val_accuracy: 0.5917\n",
            "Epoch 21/50\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.9323 - accuracy: 0.6557\n",
            "Epoch 21: val_accuracy improved from 0.59166 to 0.59180, saving model to /content/drive/MyDrive/ML Projects/Face/face_predict.h5\n",
            "448/448 [==============================] - 49s 109ms/step - loss: 0.9323 - accuracy: 0.6557 - val_loss: 1.0819 - val_accuracy: 0.5918\n",
            "Epoch 22/50\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.9066 - accuracy: 0.6655\n",
            "Epoch 22: val_accuracy improved from 0.59180 to 0.59905, saving model to /content/drive/MyDrive/ML Projects/Face/face_predict.h5\n",
            "448/448 [==============================] - 49s 109ms/step - loss: 0.9066 - accuracy: 0.6655 - val_loss: 1.0806 - val_accuracy: 0.5991\n",
            "Epoch 23/50\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.8876 - accuracy: 0.6738\n",
            "Epoch 23: val_accuracy improved from 0.59905 to 0.60128, saving model to /content/drive/MyDrive/ML Projects/Face/face_predict.h5\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.8876 - accuracy: 0.6738 - val_loss: 1.0822 - val_accuracy: 0.6013\n",
            "Epoch 24/50\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.8612 - accuracy: 0.6834\n",
            "Epoch 24: val_accuracy did not improve from 0.60128\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 0.8612 - accuracy: 0.6834 - val_loss: 1.0752 - val_accuracy: 0.6010\n",
            "Epoch 25/50\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.8398 - accuracy: 0.6938\n",
            "Epoch 25: val_accuracy improved from 0.60128 to 0.60212, saving model to /content/drive/MyDrive/ML Projects/Face/face_predict.h5\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.8398 - accuracy: 0.6938 - val_loss: 1.0740 - val_accuracy: 0.6021\n",
            "Epoch 26/50\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.8213 - accuracy: 0.6979\n",
            "Epoch 26: val_accuracy improved from 0.60212 to 0.60268, saving model to /content/drive/MyDrive/ML Projects/Face/face_predict.h5\n",
            "448/448 [==============================] - 50s 112ms/step - loss: 0.8213 - accuracy: 0.6979 - val_loss: 1.0658 - val_accuracy: 0.6027\n",
            "Epoch 27/50\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.7948 - accuracy: 0.7084\n",
            "Epoch 27: val_accuracy improved from 0.60268 to 0.60714, saving model to /content/drive/MyDrive/ML Projects/Face/face_predict.h5\n",
            "448/448 [==============================] - 49s 110ms/step - loss: 0.7948 - accuracy: 0.7084 - val_loss: 1.0743 - val_accuracy: 0.6071\n",
            "Epoch 28/50\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.7758 - accuracy: 0.7176\n",
            "Epoch 28: val_accuracy improved from 0.60714 to 0.60854, saving model to /content/drive/MyDrive/ML Projects/Face/face_predict.h5\n",
            "448/448 [==============================] - 49s 109ms/step - loss: 0.7758 - accuracy: 0.7176 - val_loss: 1.0849 - val_accuracy: 0.6085\n",
            "Epoch 29/50\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.7505 - accuracy: 0.7253\n",
            "Epoch 29: val_accuracy improved from 0.60854 to 0.61217, saving model to /content/drive/MyDrive/ML Projects/Face/face_predict.h5\n",
            "448/448 [==============================] - 50s 111ms/step - loss: 0.7505 - accuracy: 0.7253 - val_loss: 1.0825 - val_accuracy: 0.6122\n",
            "Epoch 30/50\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.7278 - accuracy: 0.7343\n",
            "Epoch 30: val_accuracy did not improve from 0.61217\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 0.7278 - accuracy: 0.7343 - val_loss: 1.0813 - val_accuracy: 0.6074\n",
            "Epoch 31/50\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.7071 - accuracy: 0.7414\n",
            "Epoch 31: val_accuracy improved from 0.61217 to 0.61593, saving model to /content/drive/MyDrive/ML Projects/Face/face_predict.h5\n",
            "448/448 [==============================] - 49s 108ms/step - loss: 0.7071 - accuracy: 0.7414 - val_loss: 1.0880 - val_accuracy: 0.6159\n",
            "Epoch 32/50\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.6886 - accuracy: 0.7494\n",
            "Epoch 32: val_accuracy improved from 0.61593 to 0.61733, saving model to /content/drive/MyDrive/ML Projects/Face/face_predict.h5\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.6886 - accuracy: 0.7494 - val_loss: 1.0871 - val_accuracy: 0.6173\n",
            "Epoch 33/50\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.6665 - accuracy: 0.7552\n",
            "Epoch 33: val_accuracy did not improve from 0.61733\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 0.6665 - accuracy: 0.7552 - val_loss: 1.0833 - val_accuracy: 0.6154\n",
            "Epoch 34/50\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.6395 - accuracy: 0.7668\n",
            "Epoch 34: val_accuracy did not improve from 0.61733\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 0.6395 - accuracy: 0.7668 - val_loss: 1.0956 - val_accuracy: 0.6145\n",
            "Epoch 35/50\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.6209 - accuracy: 0.7759\n",
            "Epoch 35: val_accuracy improved from 0.61733 to 0.61984, saving model to /content/drive/MyDrive/ML Projects/Face/face_predict.h5\n",
            "448/448 [==============================] - 50s 111ms/step - loss: 0.6209 - accuracy: 0.7759 - val_loss: 1.1071 - val_accuracy: 0.6198\n",
            "Epoch 36/50\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.6042 - accuracy: 0.7784\n",
            "Epoch 36: val_accuracy did not improve from 0.61984\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 0.6042 - accuracy: 0.7784 - val_loss: 1.1033 - val_accuracy: 0.6180\n",
            "Epoch 37/50\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.5838 - accuracy: 0.7878\n",
            "Epoch 37: val_accuracy did not improve from 0.61984\n",
            "448/448 [==============================] - 47s 106ms/step - loss: 0.5838 - accuracy: 0.7878 - val_loss: 1.1032 - val_accuracy: 0.6138\n",
            "Epoch 38/50\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.5657 - accuracy: 0.7948\n",
            "Epoch 38: val_accuracy did not improve from 0.61984\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 0.5657 - accuracy: 0.7948 - val_loss: 1.1321 - val_accuracy: 0.6184\n",
            "Epoch 39/50\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.5471 - accuracy: 0.8024\n",
            "Epoch 39: val_accuracy improved from 0.61984 to 0.62123, saving model to /content/drive/MyDrive/ML Projects/Face/face_predict.h5\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.5471 - accuracy: 0.8024 - val_loss: 1.1298 - val_accuracy: 0.6212\n",
            "Epoch 40/50\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.5228 - accuracy: 0.8121\n",
            "Epoch 40: val_accuracy did not improve from 0.62123\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 0.5228 - accuracy: 0.8121 - val_loss: 1.1414 - val_accuracy: 0.6201\n",
            "Epoch 41/50\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.5174 - accuracy: 0.8164\n",
            "Epoch 41: val_accuracy did not improve from 0.62123\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 0.5174 - accuracy: 0.8164 - val_loss: 1.1382 - val_accuracy: 0.6184\n",
            "Epoch 42/50\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.5017 - accuracy: 0.8187\n",
            "Epoch 42: val_accuracy did not improve from 0.62123\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 0.5017 - accuracy: 0.8187 - val_loss: 1.1415 - val_accuracy: 0.6203\n",
            "Epoch 43/50\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.4851 - accuracy: 0.8250\n",
            "Epoch 43: val_accuracy did not improve from 0.62123\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 0.4851 - accuracy: 0.8250 - val_loss: 1.1508 - val_accuracy: 0.6173\n",
            "Epoch 44/50\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.4639 - accuracy: 0.8325\n",
            "Epoch 44: val_accuracy did not improve from 0.62123\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.4639 - accuracy: 0.8325 - val_loss: 1.1520 - val_accuracy: 0.6191\n",
            "Epoch 45/50\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.4522 - accuracy: 0.8373\n",
            "Epoch 45: val_accuracy improved from 0.62123 to 0.62291, saving model to /content/drive/MyDrive/ML Projects/Face/face_predict.h5\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 0.4522 - accuracy: 0.8373 - val_loss: 1.1666 - val_accuracy: 0.6229\n",
            "Epoch 46/50\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.4358 - accuracy: 0.8410\n",
            "Epoch 46: val_accuracy did not improve from 0.62291\n",
            "448/448 [==============================] - 50s 111ms/step - loss: 0.4358 - accuracy: 0.8410 - val_loss: 1.1715 - val_accuracy: 0.6200\n",
            "Epoch 47/50\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.4322 - accuracy: 0.8416\n",
            "Epoch 47: val_accuracy did not improve from 0.62291\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 0.4322 - accuracy: 0.8416 - val_loss: 1.1687 - val_accuracy: 0.6211\n",
            "Epoch 48/50\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.4086 - accuracy: 0.8529\n",
            "Epoch 48: val_accuracy improved from 0.62291 to 0.62598, saving model to /content/drive/MyDrive/ML Projects/Face/face_predict.h5\n",
            "448/448 [==============================] - 49s 108ms/step - loss: 0.4086 - accuracy: 0.8529 - val_loss: 1.2091 - val_accuracy: 0.6260\n",
            "Epoch 49/50\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.4031 - accuracy: 0.8566\n",
            "Epoch 49: val_accuracy did not improve from 0.62598\n",
            "448/448 [==============================] - 49s 110ms/step - loss: 0.4031 - accuracy: 0.8566 - val_loss: 1.1911 - val_accuracy: 0.6229\n",
            "Epoch 50/50\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.3895 - accuracy: 0.8587\n",
            "Epoch 50: val_accuracy did not improve from 0.62598\n",
            "448/448 [==============================] - 47s 106ms/step - loss: 0.3895 - accuracy: 0.8587 - val_loss: 1.1963 - val_accuracy: 0.6189\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using openCV haarcascade xml detect the bounding boxes of faces in the webcam and predict the emotion:**"
      ],
      "metadata": {
        "id": "XOMvZgUrsMCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv2.ocl.setUseOpenCL(False)\n",
        "\n",
        "emotion_dict = {0: \"Angry\", 1: \"Disgusted\", 2: \"Fearful\", 3: \"Happy\", 4: \"Neutral\", 5: \"Sad\", 6: \"Surprised\"}\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    bounding_box = cv2.CascadeClassifier('/home/shivam/.local/lib/python3.6/site-packages/cv2/data/haarcascade_frontalface_default.xml')\n",
        "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2gray_frame)\n",
        "    num_faces = bounding_box.detectMultiScale(gray_frame,scaleFactor=1.3, minNeighbors=5)\n",
        "\n",
        "    for (x, y, w, h) in num_faces:\n",
        "        cv2.rectangle(frame, (x, y-50), (x+w, y+h+10), (255, 0, 0), 2)\n",
        "        roi_gray_frame = gray_frame[y:y + h, x:x + w]\n",
        "        cropped_img = np.expand_dims(np.expand_dims(cv2.resize(roi_gray_frame, (48, 48)), -1), 0)\n",
        "        emotion_prediction = emotion_model.predict(cropped_img)\n",
        "        maxindex = int(np.argmax(emotion_prediction))\n",
        "        cv2.putText(frame, emotion_dict[maxindex], (x+20, y-60), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
        "\n",
        "    cv2.imshow('Video', cv2.resize(frame,(1200,860),interpolation = cv2.INTER_CUBIC))\n",
        "    cv2.waitKey(1) & 0xFF == ord('q')\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "EC66Kft_r1jU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8_v8UscxtzSC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}